{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "# Load TinyLlama\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad token\n",
    "\n",
    "# Quantize model to 4-bit (saves VRAM)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ca236fe1dd45b780bf876737c4a8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context', 'input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "# 1. Load your custom dataset\n",
    "with open(\"data/custom_dataset_advanced.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    texts = [\n",
    "        f\"### Context:\\n{ctx}\\n\\n### Instruction:\\n{inst}\\n\\n### Response:\\n{out}\"\n",
    "        for ctx, inst, out in zip(examples[\"context\"], examples[\"instruction\"], examples[\"output\"])\n",
    "    ]\n",
    "    tokenized = tokenizer(texts, truncation=True, max_length=512, padding=\"max_length\")\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=4,\n",
    "    remove_columns=[\"instruction\", \"output\"]  # Remove original columns\n",
    ")\n",
    "\n",
    "# 4. Verify\n",
    "print(tokenized_dataset[0].keys())  # Should show: ['input_ids', 'attention_mask']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.1023\n"
     ]
    }
   ],
   "source": [
    "# LoRA settings\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                  # Rank\n",
    "    lora_alpha=32,        # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # TinyLlama layers to target\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # Should show ~0.1% trainable params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c16cc26a72434598cc6fed9d834f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Combine context, instruction, and output into the prompt\n",
    "    texts = [\n",
    "        f\"### Context:\\n{ctx}\\n\\n### Instruction:\\n{inst}\\n\\n### Response:\\n{out}\"\n",
    "        for ctx, inst, out in zip(examples[\"context\"], examples[\"instruction\"], examples[\"output\"])\n",
    "    ]\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"np\"  # Returns NumPy arrays (compatible with Trainer)\n",
    "    )\n",
    "    \n",
    "    # For causal LM, labels = input_ids (predict next token)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "# Apply to dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=4,\n",
    "    remove_columns=[\"instruction\", \"output\", \"context\"]  # Remove original columns\n",
    ")\n",
    "\n",
    "# Verify\n",
    "print(tokenized_dataset[0].keys())  # Should show: ['input_ids', 'attention_mask', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tinyllama-lora-trailtracker\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,  # Slightly lower for stability with context\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=50,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    remove_unused_columns=False,  # Required when using custom tokenization\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Simplified Trainer (no custom data collator needed)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,  # Uses pre-tokenized data with labels\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save adapter\n",
    "model.save_pretrained(\"./tinyllama-lora-trailtracker-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./outputs/tinyllama-lora-trailtracker\\\\tokenizer_config.json',\n",
       " './outputs/tinyllama-lora-trailtracker\\\\special_tokens_map.json',\n",
       " './outputs/tinyllama-lora-trailtracker\\\\tokenizer.model',\n",
       " './outputs/tinyllama-lora-trailtracker\\\\added_tokens.json',\n",
       " './outputs/tinyllama-lora-trailtracker\\\\tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the LoRA adapter (no need to save base model)\n",
    "model.save_pretrained(\"./outputs/tinyllama-lora-trailtracker\")\n",
    "tokenizer.save_pretrained(\"./outputs/tinyllama-lora-trailtracker\")  # Optional but recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# 1. Clear VRAM\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Quantization config (same as training)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# 3. Load components\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 4. Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "# 5. Load LoRA adapter (now with context support)\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    \"./outputs/tinyllama-lora-trailtracker\",  # Updated path\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Optional: Merge for faster inference (uses more VRAM)\n",
    "# model = model.merge_and_unload()\n",
    "# model.save_pretrained(\"./outputs/tinyllama-merged\")  # If merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 (with context):\n",
      "TrailTracker is a free and open-source application that helps people find hiking trails, routes, and trails in their local area.\n",
      " It is available for both Android and\n",
      "\n",
      "Test 2 (without context):\n",
      "TrailTracker offers a free trail tracker app for users who want to keep track of their hiking and trail running activities.\n",
      " The app is free to download and use, and users can create an account to access the rest of the features.\n",
      " Users can create custom tracks, set up notifications for events like trail races or fitness challenges, and share their tracks with friends and family.\n",
      "\n",
      "\n",
      "The app offers a basic free plan with limited features, such as the ability to create and share custom tracks, but users will need to pay for the premium plan for more advanced features like advanced analytics and personalized recommendations.\n",
      " The premium plan costs $10 per month or $100 per year, depending on the user's plan.\n",
      "\n",
      "\n",
      "Overall, TrailTracker's pricing is competitive and reasonable compared to other trail tracking apps.\n",
      " The free plan is a good option for users who want to keep track of their hiking\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def generate_response(instruction, context=\"\"):\n",
    "    # Format the prompt with context\n",
    "    prompt = f\"### Context:\\n{context}\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\"\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Extract and clean the response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response_text = full_response.split(\"### Response:\")[-1].strip()\n",
    "    response_text = re.sub(r'(?<!\\d)\\.(?!\\d)', '.\\n', response_text)  # Add newlines after periods\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "# Example tests\n",
    "print(\"Test 1 (with context):\")\n",
    "print(generate_response(\n",
    "    \"Who created TrailTracker?\",\n",
    "    \"Developed at Nackademin by Robert and Olle\"\n",
    "))\n",
    "\n",
    "print(\"\\nTest 2 (without context):\")\n",
    "print(generate_response(\"Describe TrailTracker's pricing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 3 (without context):\n",
      "TrailTracker is a mobile app that tracks your hiking or running adventures.\n",
      " The app allows you to log your activities and view your progress over time.\n",
      " You can also connect with other hikers and runners to share your experiences and get recommendations for new trails.\n",
      " The app is available on both Android and iOS devices and is free to download.\n",
      " It also features a social media component that allows you to share your hiking or running experiences with friends and followers.\n",
      " Overall, TrailTracker is a great tool for anyone who loves hiking or running and wants to track their progress over time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest 3 (without context):\")\n",
    "print(generate_response(\"Tell me about TrailTracker\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4 (with context):\n",
      "TrailTracker is a web app that allows users to create and manage their hiking trips.\n",
      " The app provides a user-friendly interface for creating and managing hiking routes, including the ability to add points of interest (POIs) such as trails, mountains, and waterfalls.\n",
      " Users can also customize their profiles, such as adding their hiking experience level and preferred hiking routes.\n",
      " The app also includes a map view that shows the user's current location and nearby POIs.\n",
      " Overall, TrailTracker aims to provide a seamless hiking experience by making it easy for users to plan, track, and share their hikes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test 4 (with context):\")\n",
    "print(generate_response(\n",
    "    \"Tell me about TrailTracker\",\n",
    "    \"Webapp for hike planning\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5 (with context):\n",
      "TrailTracker is a web application that allows users to plan and track their hikes.\n",
      " Users can create profiles, add hikes, and set goals for their hikes.\n",
      " They can also connect with other hikers and share their hikes with them.\n",
      " The main feature of TrailTracker is the ability to plan and track hikes.\n",
      " Users can create profiles, add hikes, and set goals for their hikes.\n",
      " They can also connect with other hikers and share their hikes with them.\n",
      " Users can also view the progress of their hikes and see how many miles they have covered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test 5 (with context):\")\n",
    "print(generate_response(\n",
    "    \"What is the main feature of TrailTracker?\",\n",
    "    \"Webapp for hike planning\"\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
